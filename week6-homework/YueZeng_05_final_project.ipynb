{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e48025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First modify the code from first sets of notebooks I used in the Community Data Science Course (Spring 2023)/Week 6 lecture to download data (and metadata) about revisions to the 5 articles you chose from Wikipedia.\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_article_revision_json_from_wikipedia(title):\n",
    "    revisions = []\n",
    "    # create a base URL for the WIKI API\n",
    "    wp_api_url = \"http://en.wikipedia.org/w/api.php\"\n",
    "    # API parameters to get revision data\n",
    "    parameters = {\n",
    "        'action': 'query',\n",
    "        'titles': title,\n",
    "        'prop': 'revisions',\n",
    "        'rvprop': 'flags|timestamp|user|size|ids',\n",
    "        'rvlimit': 500,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    while True:\n",
    "        # make API request\n",
    "        call = requests.get(wp_api_url, params=parameters)\n",
    "        # convert API response to JSON\n",
    "        api_answer = call.json()\n",
    "        # append revision data to list\n",
    "        revisions.extend(next(iter(api_answer[\"query\"][\"pages\"].values()), {}).get(\"revisions\", []))\n",
    "        # 'continue' tells us there's more revisions to add\n",
    "        if 'continue' in api_answer.keys():\n",
    "            # update parameters with continue parameter to fetch more data\n",
    "            parameters.update(api_answer['continue'])\n",
    "        else:\n",
    "            break\n",
    "    return revisions\n",
    "\n",
    "\n",
    "def get_article_pageview_json_from_wikimedia(title, start_date):\n",
    "    end_date = datetime.datetime.now().date()\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/all-agents/{title}/daily/{start_date.strftime('%Y%m%d')}/{end_date.strftime('%Y%m%d')}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'data collection from <your email address> for studing'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.status_code == 200:\n",
    "        print(\"ERROR! status was not 200\")\n",
    "    data = response.json()\n",
    "    return data[\"items\"]\n",
    "\n",
    "\n",
    "# list of Avatar-related article titles\n",
    "article_titles = [\n",
    "    'Avatar (2009 film)',\n",
    "    'Avatar: The Last Airbender',\n",
    "    'Avatar: The Last Airbender (season 1)',\n",
    "    'Avatar: The Last Airbender (season 2)',\n",
    "    'Avatar: The Last Airbender (season 3)'\n",
    "]\n",
    "\n",
    "raw_date = {title: {} for title in article_titles}\n",
    "\n",
    "data = {title: {} for title in article_titles}\n",
    "\n",
    "\n",
    "for title in article_titles:\n",
    "    revisions = get_article_revision_json_from_wikipedia(title)\n",
    "    start_date = datetime.datetime.strptime(min(map(lambda revision: revision[\"timestamp\"], revisions)), \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=datetime.timezone.utc).astimezone(tz=None)\n",
    "    pageviews = get_article_pageview_json_from_wikimedia(title, start_date)\n",
    "    raw_date[title] = {\"revisions\": revisions, \"pageviews\": pageviews}\n",
    "\n",
    "with open(\"raw_data.json\", \"w\") as file_out:\n",
    "    json.dump(raw_date, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e168e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in article_titles:\n",
    "    with open(f\"{title}.tsv\", \"w\") as file_out:\n",
    "        file_out.write(\"date\\trevision\\tsize\\tsize_diff\\tviews\\n\")\n",
    "        last_size = 0\n",
    "        for date in sorted(data[title].keys()):\n",
    "            curr_size = data[title][date].get(\"size\", last_size)\n",
    "            size_diff = abs(last_size - curr_size)\n",
    "            last_size = curr_size\n",
    "            file_out.write(f\"{date}\\t{data[title][date].get('revision_count', 0)}\\t{curr_size}\\t{size_diff}\\t{data[title][date].get('views', 0)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe55360",
   "metadata": {},
   "source": [
    "1. What is your proposed unit of analysis? In other words, if/when you end up building something like a spreadsheet, what are rows going to represent?\n",
    "\n",
    "Rows represent date\n",
    "\n",
    "2. What specific measures associated with each unit do you want to collect? In other words, what are the columns in the spreadsheet going to be?\n",
    "\n",
    "Columns are some data like size, differences of size(The size of the wiki content and the amount of change compared to the previous day), revision count, and dataviews. \n",
    "\n",
    "3. Tell us what you've learned about the API:\n",
    "    Are you going to be able to get the data you want with one API call or many? If more than one, how many?\n",
    "    If it's more than one call, how will you know when you have collected all your data?\n",
    "\n",
    "For revision, use many call to get data, for pageview, use one call. Judging whether the data acquisition is completed by whether there is a continue flag\n",
    "\n",
    "4. Make one API call and save the output to your desk in either a .json or .jsonl file. Be sure to share the code you used to do this. Be sure not to include any API keys in your notebook!\n",
    "\n",
    "I save all data to raw_data.json\n",
    "\n",
    "5. How big is the JSON file that you saved on your disk (i.e., in bytes or kilobytes)? If it is not your full dataset, what is your estimate for how much larger the full dataset will be? How big will the total dataset be? Is that a problem?\n",
    "\n",
    "It's 6,562,283 B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
