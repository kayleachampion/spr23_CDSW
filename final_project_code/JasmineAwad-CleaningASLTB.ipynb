{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebb9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b6ab17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the larger folder containing the participant data\n",
    "folder_path = \"C:/Users/Jasmine Awad/Desktop/COMS Data Science/RawDataASLTB\"\n",
    "\n",
    "# Define the participant ID (I do this for each participant to check for errors)\n",
    "participant_list = os.listdir(folder_path)\n",
    "\n",
    "\n",
    "# define correct thingys\n",
    "CorrRespST = ['brother and wife (sister in law)', \n",
    "              'using the restroom makes noise', \n",
    "              'ASL instructor', \n",
    "              'Bangladesh', \n",
    "              'Australia', \n",
    "              'Date cookie']\n",
    "CorrRespMaze = {'ASLCompStim1.jpg':'[\"purse\",\"store\",\"balloon\"]', \n",
    "                'ASLCompStim2.jpg':'[\"flower\",\"dog\",\"balloon\"]', \n",
    "                'ASLCompStim3.jpg':'[\"bike\",\"balloon\",\"hospital\"]',\n",
    "                'ASLCompStim4.jpg':'[\"purse\",\"hospital\",\"store\"]', \n",
    "                'ASLCompStim5.jpg':'[\"dog\",\"store\",\"bike\"]', \n",
    "                'ASLCompStim6.jpg':'[\"flower\",\"store\",\"balloon\"]'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "320bf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C01', 'C02', 'C05', 'C08', 'C09', 'C10', 'C11', 'C17', 'CleanedData', 'D02', 'D03', 'D05', 'D06', 'H02', 'H03', 'H05', 'H07', 'H08', 'H09', 'H12', 'H13', 'H14', 'H15', 'H18', 'S02', 'S03', 'S04', 'S05', 'S06', 'S07', 'S08', 'S09', 'S11', 'T04', 'T05', 'T08']\n"
     ]
    }
   ],
   "source": [
    "print(participant_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a744830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing and column addition completed successfully for C01.\n",
      "Data processing and column addition completed successfully for C02.\n",
      "Data processing and column addition completed successfully for C05.\n",
      "Data processing and column addition completed successfully for C08.\n",
      "Data processing and column addition completed successfully for C09.\n",
      "Data processing and column addition completed successfully for C10.\n",
      "Data processing and column addition completed successfully for C11.\n",
      "Data processing and column addition completed successfully for C17.\n",
      "CleanedData is a bad person and they should feel bad!!\n",
      "Data processing and column addition completed successfully for D02.\n",
      "Data processing and column addition completed successfully for D03.\n",
      "Data processing and column addition completed successfully for D05.\n",
      "Data processing and column addition completed successfully for D06.\n",
      "Data processing and column addition completed successfully for H02.\n",
      "Data processing and column addition completed successfully for H03.\n",
      "Data processing and column addition completed successfully for H05.\n",
      "Data processing and column addition completed successfully for H07.\n",
      "Data processing and column addition completed successfully for H08.\n",
      "Data processing and column addition completed successfully for H09.\n",
      "Data processing and column addition completed successfully for H12.\n",
      "Data processing and column addition completed successfully for H13.\n",
      "Data processing and column addition completed successfully for H14.\n",
      "Data processing and column addition completed successfully for H15.\n",
      "Data processing and column addition completed successfully for H18.\n",
      "Data processing and column addition completed successfully for S02.\n",
      "Data processing and column addition completed successfully for S03.\n",
      "Data processing and column addition completed successfully for S04.\n",
      "Data processing and column addition completed successfully for S05.\n",
      "Data processing and column addition completed successfully for S06.\n",
      "Data processing and column addition completed successfully for S07.\n",
      "Data processing and column addition completed successfully for S08.\n",
      "Data processing and column addition completed successfully for S09.\n",
      "Data processing and column addition completed successfully for S11.\n",
      "Data processing and column addition completed successfully for T04.\n",
      "Data processing and column addition completed successfully for T05.\n",
      "Data processing and column addition completed successfully for T08.\n"
     ]
    }
   ],
   "source": [
    "for participant_id in participant_list:\n",
    "    # Construct the path to the participant's folder\n",
    "    participant_folder = os.path.join(folder_path, participant_id)\n",
    "    \n",
    "    # Check if the participant's folder exists\n",
    "    if os.path.exists(participant_folder):\n",
    "        # Get a list of files in the participant's folder\n",
    "        files = os.listdir(participant_folder)\n",
    "\n",
    "\n",
    "        # Filter out any subdirectories from the list of files\n",
    "        raw_files = [file for file in files if os.path.isfile(os.path.join(participant_folder, file))]\n",
    "\n",
    "        # Flag to indicate if the ASLTestBattery1 file is found\n",
    "        found_asl_test_battery1 = False\n",
    "        # Flag to indicate if the ASLTestBattery2 file is found\n",
    "        found_asl_test_battery2 = False\n",
    "\n",
    "        # Dataframes to store the cleaned data\n",
    "        cleaned_data1 = None\n",
    "        cleaned_data2 = None\n",
    "\n",
    "        # Process each raw data file\n",
    "        for raw_file in raw_files:\n",
    "            # Check if the current file is the \"ASLTestBattery1\" file\n",
    "            if \"ASLTestBattery1\" in raw_file:\n",
    "                found_asl_test_battery1 = True\n",
    "\n",
    "                # Construct the path to the raw data file\n",
    "                file_path = os.path.join(participant_folder, raw_file)\n",
    "\n",
    "                # Load the raw data file into a pandas DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Extract the columns of interest from ASLTestBattery1\n",
    "                typed_word = df[\"typedWord\"]\n",
    "                item_prompt = df[\"itemPrompt\"]\n",
    "                image_file = df[\"imageFile\"]\n",
    "                clicked_response = df[\"mouse_2.clicked_name\"]\n",
    "\n",
    "                # Remove blank rows from the imageFile column and reset index\n",
    "                image_file = image_file.dropna().reset_index(drop=True)\n",
    "\n",
    "                # Remove blank rows from the mouse_2.clicked_name column and reset index\n",
    "                clicked_response = clicked_response.dropna().reset_index(drop=True)\n",
    "\n",
    "                # Perform data cleaning or any other desired operations on the extracted columns\n",
    "                # ...\n",
    "\n",
    "                # Combine the extracted columns into a DataFrame\n",
    "                cleaned_data1 = pd.DataFrame({\"typedWord\": typed_word, \"itemPrompt\": item_prompt, \"imageFile\": image_file, \"mouse_2.clicked_name\": clicked_response})\n",
    "\n",
    "            # Check if the current file is the \"ASLTestBattery2\" file\n",
    "            if \"ASLTestBattery2\" in raw_file:\n",
    "                found_asl_test_battery2 = True\n",
    "\n",
    "                # Construct the path to the raw data file\n",
    "                file_path = os.path.join(participant_folder, raw_file)\n",
    "\n",
    "                # Load the raw data file into a pandas DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Extract the columns of interest from ASLTestBattery2\n",
    "                typed_word2 = df[\"typedWord\"]\n",
    "                FSvideo_file = df[\"videoFile\"][:10]  # Extract the first 10 rows\n",
    "                Matchvideo_file = df[\"videoFile\"][10:] #extract the rest\n",
    "                MatchResponse = df[\"resp.clicked_name\"]\n",
    "                Match_CorrAns = df[\"corrAns\"]\n",
    "\n",
    "                # Remove blank rows from the match Response column and reset index\n",
    "                MatchResponse = MatchResponse.dropna().reset_index(drop=True)\n",
    "\n",
    "                # Remove blank rows from the image drawn column and reset index\n",
    "                Image_Drawn = Image_Drawn.dropna().reset_index(drop=True)\n",
    "\n",
    "                # Remove blank rows from the corrAns column and reset index\n",
    "                Match_CorrAns = Match_CorrAns.dropna().reset_index(drop=True)\n",
    "\n",
    "                # Perform data cleaning or any other desired operations on the extracted columns\n",
    "                # ...\n",
    "\n",
    "                # Combine the extracted columns into a DataFrame\n",
    "                cleaned_data2 = pd.DataFrame({\"typedWord2\": typed_word2, \"videoFile\": FSvideo_file,\n",
    "                                              \"matchResponse\": MatchResponse, \"imageDrawn\": Image_Drawn,\n",
    "                                              \"matchCorrAns\": Match_CorrAns})\n",
    "\n",
    "        # Combine the cleaned data from ASLTestBattery1 and ASLTestBattery2, if available\n",
    "    if cleaned_data1 is not None and cleaned_data2 is not None:\n",
    "        cleaned_data = pd.concat([cleaned_data1, cleaned_data2], axis=1)\n",
    "\n",
    "        # Add the additional columns with blank values\n",
    "        num_rows = len(cleaned_data)\n",
    "\n",
    "        # Create the columns with NaN values\n",
    "        cleaned_data['CorrRespST'] = np.nan\n",
    "        cleaned_data['CorrRespMaze'] = np.nan\n",
    "        cleaned_data['MatchCorrect'] = np.nan\n",
    "\n",
    "        # Assign the values to the respective columns\n",
    "        cleaned_data.loc[:len(CorrRespST)-1, 'CorrRespST'] = CorrRespST\n",
    "        for img in CorrRespMaze:\n",
    "            cleaned_data.loc[cleaned_data['imageFile'] == img, 'CorrRespMaze'] = CorrRespMaze[img]\n",
    "        for i in range(len(MatchResponse)):\n",
    "            if MatchResponse[i] == Match_CorrAns[i]:\n",
    "                cleaned_data.loc[i, 'MatchCorrect'] = 1\n",
    "            else:\n",
    "                cleaned_data.loc[i, 'MatchCorrect'] = 0\n",
    "\n",
    "        # Save the cleaned data to a new file\n",
    "        cleaned_data.to_csv(folder_path + \"/CleanedData/\" + participant_id + '_cleaned.csv', index=False)\n",
    "\n",
    "        # Print a message indicating successful completion\n",
    "        print(f\"Data processing and column addition completed successfully for {participant_id}.\")\n",
    "    else:\n",
    "        print(f\"{participant_id} is a bad person and they should feel bad!!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
