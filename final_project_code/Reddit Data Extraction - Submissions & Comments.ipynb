{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa48f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36858bb9",
   "metadata": {},
   "source": [
    "## Decompressing .zst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ce6f04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SkincareSubmissions = []\n",
    "\n",
    "with open(\"SkincareAddiction_submissions.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        SkincareSubmissions.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c18ec258",
   "metadata": {},
   "outputs": [],
   "source": [
    "SkincareComments = []\n",
    "\n",
    "with open(\"SkincareAddiction_comments.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        SkincareComments.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "910eb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeupSubmissions = []\n",
    "\n",
    "with open(\"MakeupAddiction_submissions.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        MakeupSubmissions.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d22d16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MakeupComments  = []\n",
    "\n",
    "with open(\"MakeupAddiction_comments.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        MakeupComments.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a040d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HomeDecoratingSubmissions = []\n",
    "\n",
    "with open(\"HomeDecorating_submissions.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        HomeDecoratingSubmissions.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2524dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "HomeDecoratingComments = []\n",
    "\n",
    "with open(\"HomeDecorating_comments.zst\", 'rb') as fh:\n",
    "    dctx = zstandard.ZstdDecompressor()\n",
    "    stream_reader = dctx.stream_reader(fh)\n",
    "    text_stream = io.TextIOWrapper(stream_reader, encoding='utf-8')\n",
    "    for line in text_stream:\n",
    "        HomeDecoratingComments.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f15f3",
   "metadata": {},
   "source": [
    "## Making .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ebf907fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SkincareSubmissions.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(SkincareSubmissions)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b616eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SkincareComments.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(SkincareComments)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb8230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MakeupSubmissions.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(MakeupSubmissions)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MakeupComments.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(MakeupComments)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ba6b81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HomeDecoratingSubmissions.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(HomeDecoratingSubmissions)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9680dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HomeDecoratingComments.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(HomeDecoratingSubmissions)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d8f70",
   "metadata": {},
   "source": [
    "## Reading data from .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b611c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('SkincareSubmissions.json', 'r') as input_file :\n",
    "    input_data = input_file.read()\n",
    "    \n",
    "SkincareSubs = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fb95662",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('MakeupSubmissions.json', 'r') as input_file :\n",
    "    input_data = input_file.read()\n",
    "    \n",
    "MakeupSubs = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b3864e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('HomeDecoratingSubmissions.json', 'r') as input_file :\n",
    "    input_data = input_file.read()\n",
    "    \n",
    "HomeSubs = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8bd7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('HomeDecoratingComments.json', 'r') as input_file :\n",
    "    input_data = input_file.read()\n",
    "    \n",
    "HomeComments = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea0058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('SkincareComments.json', 'r') as input_file :\n",
    "    input_data = input_file.read()\n",
    "    \n",
    "SkincareComments = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2ada92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"downs\":1,\"link_flair_text\":null,\"distinguished\":null,\"media\":null,\"url\":\"http://trendslidingdoors.com/simple-christmas-door-decorations\",\"link_flair_css_class\":null,\"id\":\"nfzfl\",\"edited\":false,\"num_reports\":null,\"created_utc\":1324093696,\"banned_by\":null,\"name\":\"t3_nfzfl\",\"subreddit\":\"HomeDecorating\",\"title\":\"Simple Christmas Door Decorations\",\"author_flair_text\":null,\"is_self\":false,\"author\":\"sleepyblogger\",\"media_embed\":{},\"permalink\":\"/r/HomeDecorating/comments/nfzfl/simple_christmas_door_decorations/\",\"author_flair_css_class\":null,\"selftext\":\"\",\"domain\":\"trendslidingdoors.com\",\"num_comments\":0,\"likes\":null,\"clicked\":false,\"thumbnail\":\"default\",\"saved\":false,\"subreddit_id\":\"t5_2t8de\",\"ups\":1,\"approved_by\":null,\"score\":0,\"selftext_html\":null,\"created\":1324093696,\"hidden\":false,\"over_18\":false}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HomeComments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1473e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"edited\":false,\"ups\":1,\"created_utc\":\"1326236325\",\"author_flair_text\":null,\"archived\":true,\"gilded\":0,\"score_hidden\":false,\"controversiality\":0,\"subreddit\":\"SkincareAddiction\",\"body\":\"I just tried a sample bottle of Caudalie\\'s Premier Cru face cream. I glowed for 2 days after. It\\'s $150 Cdn a bottle. While I can afford this (somewhat)- I can make it work- I have just set a budget that does not allow for $150 on face cream unless I can make the bottle last all year! lol\",\"link_id\":\"t3_ob7gk\",\"id\":\"c3fwnp5\",\"subreddit_id\":\"t5_2tbbg\",\"author\":\"Spawned2\",\"score\":1,\"name\":\"t1_c3fwnp5\",\"distinguished\":null,\"retrieved_on\":1428157795,\"downs\":0,\"author_flair_css_class\":null,\"parent_id\":\"t1_c3fw9l0\"}\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SkincareComments[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe57759",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae72d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getYear (timestamp):\n",
    "    date = datetime.fromtimestamp(int(timestamp))\n",
    "    return date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b61fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_timestamp (timestamp):\n",
    "    return (datetime.fromtimestamp(int(timestamp)).strftime(\"%m-%d-%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46941c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_selftext (selftext):\n",
    "    selftext = selftext.replace('\\n', ' ')\n",
    "    selftext = selftext.replace('\\t', ' ')\n",
    "    return selftext "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8934b9b",
   "metadata": {},
   "source": [
    "## Create .tsv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b30c",
   "metadata": {},
   "source": [
    "### SkincareSubs.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07c09e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.38436007499695 seconds\n"
     ]
    }
   ],
   "source": [
    "# url, created_utc, subreddit, title, selftext, num_comments, ups, subreddit_id\n",
    "i = 0\n",
    "total_i = len(SkincareSubs)\n",
    "start_time = time.time()\n",
    "with open('SkincareSubs.tsv', 'w') as output_file:\n",
    "    print (\"url\\tcreated_utc\\tsubreddit\\ttitle\\tselftext\\tnum_comments\\tups\\tsubreddit_id\", file=output_file)\n",
    "    \n",
    "    \n",
    "    for sub in SkincareSubs:\n",
    "        \n",
    "        subJSON = json.loads(sub)\n",
    "        currentYear = getYear(subJSON[\"created_utc\"])\n",
    "        \n",
    "        try:\n",
    "            if currentYear >= 2019:\n",
    "                ups = np.nan if \"ups\" not in list(subJSON.keys()) else subJSON[\"ups\"]\n",
    "                print (f'{subJSON[\"url\"]}\\t{pd.to_datetime(sanitize_timestamp (subJSON[\"created_utc\"]))}\\t{subJSON[\"subreddit\"]}\\t{subJSON[\"title\"]}\\t{sanitize_selftext(subJSON[\"selftext\"])}\\t{subJSON[\"num_comments\"]}\\t{ups}\\t{subJSON[\"subreddit_id\"]}', file=output_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "print (f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d387393",
   "metadata": {},
   "source": [
    "### MakeupSubs.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d577a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.018593072891235 seconds\n"
     ]
    }
   ],
   "source": [
    "# url, created_utc, subreddit, title, selftext, num_comments, ups, subreddit_id\n",
    "i = 0\n",
    "total_i = len(MakeupSubs)\n",
    "start_time = time.time()\n",
    "with open('MakeupSubs.tsv', 'w') as output_file:\n",
    "    print (\"url\\tcreated_utc\\tsubreddit\\ttitle\\tselftext\\tnum_comments\\tups\\tsubreddit_id\", file=output_file)\n",
    "    \n",
    "    \n",
    "    for sub in MakeupSubs:\n",
    "        \n",
    "        subJSON = json.loads(sub)\n",
    "        currentYear = getYear(subJSON[\"created_utc\"])\n",
    "        \n",
    "        try:\n",
    "            if currentYear >= 2019:\n",
    "                ups = np.nan if \"ups\" not in list(subJSON.keys()) else subJSON[\"ups\"]\n",
    "                print (f'{subJSON[\"url\"]}\\t{sanitize_timestamp (subJSON[\"created_utc\"])}\\t{subJSON[\"subreddit\"]}\\t{subJSON[\"title\"]}\\t{sanitize_selftext(subJSON[\"selftext\"])}\\t{subJSON[\"num_comments\"]}\\t{ups}\\t{subJSON[\"subreddit_id\"]}', file=output_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "print (f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f432fd5",
   "metadata": {},
   "source": [
    "### HomeSubs.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a97935c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.45243501663208 seconds\n"
     ]
    }
   ],
   "source": [
    "# url, created_utc, subreddit, title, selftext, num_comments, ups, subreddit_id\n",
    "i = 0\n",
    "total_i = len(HomeSubs)\n",
    "start_time = time.time()\n",
    "with open('HomeSubs.tsv', 'w') as output_file:\n",
    "    print (\"url\\tcreated_utc\\tsubreddit\\ttitle\\tselftext\\tnum_comments\\tups\\tsubreddit_id\", file=output_file)\n",
    "    \n",
    "    \n",
    "    for sub in HomeSubs:\n",
    "        \n",
    "        subJSON = json.loads(sub)\n",
    "        currentYear = getYear(subJSON[\"created_utc\"])\n",
    "        \n",
    "        try:\n",
    "            if currentYear >= 2019:\n",
    "                ups = np.nan if \"ups\" not in list(subJSON.keys()) else subJSON[\"ups\"]\n",
    "                print (f'{subJSON[\"url\"]}\\t{sanitize_timestamp (subJSON[\"created_utc\"])}\\t{subJSON[\"subreddit\"]}\\t{subJSON[\"title\"]}\\t{sanitize_selftext(subJSON[\"selftext\"])}\\t{subJSON[\"num_comments\"]}\\t{ups}\\t{subJSON[\"subreddit_id\"]}', file=output_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "print (f\"{time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b452e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.01282620429993 seconds\n"
     ]
    }
   ],
   "source": [
    "#author, created_utc, body, link_id, parent_id, id\n",
    "\n",
    "i = 0\n",
    "total_i = len(SkincareComments)\n",
    "start_time = time.time()\n",
    "with open('SkincareComments.tsv', 'w') as output_file:\n",
    "    print (\"author\\tcreated_utc\\tbody\\tlink_id\\tparent_id\\tid\", file=output_file)\n",
    "    \n",
    "    \n",
    "    for com in SkincareComments:\n",
    "        \n",
    "        SComsJson = json.loads(com)\n",
    "        currentYear = getYear(SComsJson[\"created_utc\"])\n",
    "        \n",
    "        try:\n",
    "            if currentYear >= 2019:\n",
    "                print (f'{SComsJson[\"author\"]}\\t{sanitize_timestamp(SComsJson[\"created_utc\"])}\\t{sanitize_selftext(SComsJson[\"body\"])}\\t{SComsJson[\"link_id\"]}\\t{SComsJson[\"parent_id\"]}\\t{SComsJson[\"id\"]}', file=output_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "print (f\"{time.time() - start_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff369b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.01282620429993 seconds\n"
     ]
    }
   ],
   "source": [
    "#author, created_utc, body, link_id, parent_id, id\n",
    "\n",
    "i = 0\n",
    "total_i = len(HomeComments)\n",
    "start_time = time.time()\n",
    "with open('HomeComments.tsv', 'w') as output_file:\n",
    "    print (\"author\\tcreated_utc\\tbody\\tlink_id\\tparent_id\\tid\", file=output_file)\n",
    "    \n",
    "    \n",
    "    for com in SkincareComments:\n",
    "        \n",
    "        SComsJson = json.loads(com)\n",
    "        currentYear = getYear(SComsJson[\"created_utc\"])\n",
    "        \n",
    "        try:\n",
    "            if currentYear >= 2019:\n",
    "                print (f'{SComsJson[\"author\"]}\\t{sanitize_timestamp(SComsJson[\"created_utc\"])}\\t{sanitize_selftext(SComsJson[\"body\"])}\\t{SComsJson[\"link_id\"]}\\t{SComsJson[\"parent_id\"]}\\t{SComsJson[\"id\"]}', file=output_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "        i += 1\n",
    "        \n",
    "print (f\"{time.time() - start_time} seconds\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
