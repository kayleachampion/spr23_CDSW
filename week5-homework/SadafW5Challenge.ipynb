{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "256e1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3432a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/user/Gilles_Deleuze/daily/20010101/20230430\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9db2beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'python data collection bot by ssadrii@uw.edu',\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "if not response.status_code == 200:\n",
    "    print (\"Error\")\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "547bcb0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2860"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea3f0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Deleuze.json\", 'w') as f:\n",
    "    data_string = json.dumps(data)\n",
    "    print(data_string, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "281a6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Deleuze.json\", 'r') as f:\n",
    "    new_data_string = f.read()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a416a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = json.loads(new_data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17a4b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikimedia_timestamp (old_date_string):\n",
    "    new_date_string = f\"{old_date_string[0:4]}-{old_date_string[4:6]}-{old_date_string[6:8]}\"\n",
    "    return new_date_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "273747b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeDaily.tsv\", \"w\") as f:\n",
    "    print(\"day\\tviews\", file=f)\n",
    "    \n",
    "    for day_dict in new_data[\"items\"]:\n",
    "        day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "        views = day_dict[\"views\"]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e67da8",
   "metadata": {},
   "source": [
    "Link: https://docs.google.com/spreadsheets/d/1YA3FjxmXolGSiGaFHn0xtTO9mPjnO7HVMSXyl2yGvqM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c912074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Deleuze in Farsi\n",
    "url = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/fa.wikipedia.org/all-access/user/%DA%98%DB%8C%D9%84_%D8%AF%D9%84%D9%88%D8%B2/daily/200210101/20230430\"\n",
    "headers = {\n",
    "    'User-Agent': 'python data collection bot by ssadrii@uw.edu',\n",
    "}\n",
    "responseFa = requests.get(url, headers=headers)\n",
    "if not responseFa.status_code == 200:\n",
    "    print (\"Error\")\n",
    "dataFa = responseFa.json()\n",
    "len(dataFa[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "15b2525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeFa.json\", 'w') as f:\n",
    "    data_string_FA = json.dumps(dataFa)\n",
    "    print(data_string_FA, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e19f0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeFa.json\", 'r') as f:\n",
    "    new_data_string_FA = f.read()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aaf58e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_Fa = json.loads(new_data_string_FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e44d7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikimedia_timestamp (old_date_string):\n",
    "    new_date_string_FA = f\"{old_date_string[0:4]}-{old_date_string[4:6]}-{old_date_string[6:8]}\"\n",
    "    return new_date_string_FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38bd65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeFa.tsv\", \"w\") as f:\n",
    "    print(\"day\\tviews\", file=f)\n",
    "    \n",
    "    for day_dict in new_data_Fa [\"items\"]:\n",
    "        day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "        views = day_dict[\"views\"]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c016792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleuze in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99634ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/es.wikipedia.org/all-access/user/Gilles_Deleuze/daily/20010101/20230428\"\n",
    "headers = {\n",
    "    'User-Agent': 'python data collection bot by ssadrii@uw.edu',\n",
    "}\n",
    "responseEs = requests.get(url, headers=headers)\n",
    "if not responseEs.status_code == 200:\n",
    "    print (\"Error\")\n",
    "dataEs = responseEs.json()\n",
    "len(dataEs[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "653b5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeEs.json\", 'w') as f:\n",
    "    data_string_ES = json.dumps(dataEs)\n",
    "    print(data_string_ES, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a12ff457",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeEs.json\", 'r') as f:\n",
    "    new_data_string_Es = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8141f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_Es = json.loads(new_data_string_Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "41ace504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikimedia_timestamp (old_date_string):\n",
    "    new_date_string_Es = f\"{old_date_string[0:4]}-{old_date_string[4:6]}-{old_date_string[6:8]}\"\n",
    "    return new_date_string_Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e22bba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DeleuzeEs.tsv\", \"w\") as f:\n",
    "    print(\"day\\tviews\", file=f)\n",
    "    \n",
    "    for day_dict in new_data_Es [\"items\"]:\n",
    "        day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "        views = day_dict[\"views\"]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link = https://docs.google.com/spreadsheets/d/1_d_zRFNWiypFsQy-EbI3p4xFoAY4alb-pucpDqQL7tw/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "949ee7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def get_wikipedia_pageviews(page_title, wikipediaUrl):\n",
    "    url = (\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/\" + \n",
    "           f\"{wikipediaUrl}/all-access/user/{page_title}/daily/20010101/20230424\")\n",
    "    headers = {\n",
    "        'User-Agent': 'python data collection bot by ssadrii@uw.edu'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if not response.status_code == 200:\n",
    "        print(\"ERROR, request not OK\")\n",
    "    \n",
    "    data = response.json()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "eb5998cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataM = get_wikipedia_pageviews(\"Marvel_Comics\", \"en.wikipedia.org\")\n",
    "with open(\"MARVELViews.json\", 'w') as my_file:\n",
    "    data_string_Marvel = json.dumps(dataM)\n",
    "    print(data_string_Marvel, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23cb86a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (dataM[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "555718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MARVELViews.json\", 'r') as input_file:\n",
    "    input_data = input_file.read()\n",
    "    new_data_Marvel = json.loads(input_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b732fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_Marvel = json.loads(new_data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "870bb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikimedia_timestamp (old_date_string):\n",
    "    new_date_string = f\"{old_date_string[0:4]}-{old_date_string[4:6]}-{old_date_string[6:8]}\"\n",
    "    return new_date_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "19cd5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MARVELViews.tsv\", \"w\") as f:\n",
    "    print(\"day\\tviews\", file=f)\n",
    "    \n",
    "    for day_dict in new_data_Marvel [\"items\"]:\n",
    "        day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "        views = day_dict[\"views\"]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "933bc17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvel total views are 305421\n"
     ]
    }
   ],
   "source": [
    "total_views = 0\n",
    "for item in new_data_Marvel['items']:\n",
    "    if '2022' in item['timestamp']:\n",
    "        total_views = total_views + item['views']\n",
    "\n",
    "print(\"Marvel total views are\", total_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "80cf2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDC = get_wikipedia_pageviews(\"DC_Comics\", \"en.wikipedia.org\")\n",
    "with open(\"DCViews.json\", 'w') as my_file:\n",
    "    data_stringDC = json.dumps(dataDC)\n",
    "    print(data_stringDC, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ec1d409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2855"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (dataDC[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b93cc253",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DCViews.json\", 'r') as input_file:\n",
    "    input_data = input_file.read()\n",
    "    new_data_DC = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79243821",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_DC = json.loads(new_data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a3f4e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wikimedia_timestamp (old_date_string):\n",
    "    new_date_string = f\"{old_date_string[0:4]}-{old_date_string[4:6]}-{old_date_string[6:8]}\"\n",
    "    return new_date_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bb713dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DCViews.tsv\", \"w\") as f:\n",
    "    print(\"day\\tviews\", file=f)\n",
    "    \n",
    "    for day_dict in new_data_DC [\"items\"]:\n",
    "        day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "        views = day_dict[\"views\"]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b7808a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC views has been  305421\n"
     ]
    }
   ],
   "source": [
    "total_views = 0\n",
    "for item in new_data_DC['items']:\n",
    "    if '2022' in item['timestamp']:\n",
    "        total_views = total_views + item['views']\n",
    "\n",
    "print(\"DC views has been \", total_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43439947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0198df1b",
   "metadata": {},
   "source": [
    "Hmm  wait why am I getting weird results for all these? I feel like i've checked my variable names 1000 times lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbffdd",
   "metadata": {},
   "source": [
    "TRYING MAKO's WAY so maybe that one works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ee343783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pageview_data (page_title):\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'data collection from ssadrii@uw.edu'\n",
    "    }\n",
    "\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/{page_title}/daily/20010101/20230401\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81ee090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC Comics\n",
      "Marvel Comics\n"
     ]
    }
   ],
   "source": [
    "for title in [\"DC Comics\", \"Marvel Comics\"]:\n",
    "    data = get_pageview_data(title)\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1254c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"COMBODCMARVEL.jsonl\", 'w') as f:\n",
    "    for title in [\"DC Comics\", \"Marvel Comics\"]:\n",
    "        data = get_pageview_data(title)\n",
    "        data_string = json.dumps(data)\n",
    "        print(data_string, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "aaa56cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dicts = []\n",
    "with open(\"COMBODCMARVEL.jsonl\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        json_data = json.loads(line)\n",
    "        day_dicts.extend(json_data[\"items\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "87b62e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_views_by_day = {} \n",
    "\n",
    "for day_dict in day_dicts:\n",
    "    day = parse_wikimedia_timestamp(day_dict[\"timestamp\"])\n",
    "    if day in total_views_by_day:\n",
    "        total_views_by_day[day] = total_views_by_day[day] + day_dict['views']\n",
    "    else:\n",
    "        total_views_by_day[day] = day_dict[\"views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c22bcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"COMBODCMARVEL.tsv\", \"w\") as f:\n",
    "    print(\"day\\ttotal_views\", file=f)\n",
    "    \n",
    "    for day in total_views_by_day.keys():\n",
    "        views = total_views_by_day[day]\n",
    "        print(day, \"\\t\", views, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed57cc",
   "metadata": {},
   "source": [
    "I am very confused at this point with my coding \n",
    "I'll move to the next one and learn what I am doing wrong tomorrow\n",
    "It seems pretty straightforward but I hate it :)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0edf1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'website': 'en.wikipedia.org', 'page_title': 'Nirvana_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Presidents_of_the_United_States_of_America_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Soundgarden'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Sleater-Kinney'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mother_Love_Bone'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Beat_Happening'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Bratmobile'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Temple_of_the_Dog'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mudhoney'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Modest_Mouse'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Postal_Service'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Sunny_Day_Real_Estate'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Green_River_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mad_Season_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'United_State_of_Electronica'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Foo_Fighters'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Candlebox'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Death_Cab_for_Cutie'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Pedro_the_Lion'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Dub_Narcotic_Sound_System'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Ugly_Casanova'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Tad_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Microphones'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Harvey_Danger'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Malfunkshun'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Chaos_Chaos'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Vendetta_Red'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Minus_the_Bear'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Dolour'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Gas_Huffer'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mount_Eerie'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Brad_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Satchel_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Briefs'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Poor_Old_Lu'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Love_as_Laughter'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Makers_(American_band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Bangs_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Eureka_Farm'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Posies'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'This_Busy_Monster'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Gatsbys_American_Dream'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Long_Winters'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Voyager_One_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Trachtenburg_Family_Slideshow_Players'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Wellwater_Conspiracy'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Western_State_Hurricanes'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Gossip_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Say_Hi'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Prom_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Young_Fresh_Fellows'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Listening_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Walkabouts'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Band_of_Horses'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Vells'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Crooked_Fingers'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_U-Men'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Aqueduct_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Red_Stars_Theory'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': '764-HERO'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Old_Time_Relijun'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Headphones_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Sledgeback'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Pearl_Jam'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Turn-Ons'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Shoplifting_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Classic_Crime'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Fair_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Waxwing_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'This_Providence'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'D+_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Unified_Theory_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': \"Carissa's_Wierd\"}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Tullycraft'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Beehive_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Shotty'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Room_Nine'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Lights'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Hovercraft_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Six_Cents_and_Natalie'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Rockfords'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Crayon_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Truly_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Grand_Archives'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Intelligence'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Sweet_Water_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Lonely_Forest'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Little_Champions'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Fall_from_Grace_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Math_and_Physics_Club'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Magic_Magicians'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Pharmacy'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Cave_Singers'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Super_Deluxe_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Throw_Me_the_Statue'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Kay_Kay_and_His_Weathered_Underground'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Myriad'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Grand_Hallway'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Old_Haunts'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Enation_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Danger_Radio'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Some_By_Sea'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Blakes'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Brite_Futures'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'His_Boy_Elroy'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Devilhead'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Kate_Tucker_&_the_Sons_of_Sweden'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Daphne_Loves_Derby'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Ghost_and_the_Grace'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Telekinesis_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mt._St._Helens_Vietnam_Band'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Tea_Cozies'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Helvetia_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Doll_Factory'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Nightgowns'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Nevada_Bachelors'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Roman_Holiday_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Ivan_&_Alyosha'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Rodney_&_the_Tube_Tops'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'He_Is_We'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Fences_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Head_and_the_Heart'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Too_Slim_and_the_Taildraggers'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Lake_(American_band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Calm_Down_Juanita'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Actual_Tigers'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Doll_Squad'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Revolutionary_Hydra'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'A_Gun_That_Shoots_Knives'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Juned'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Pollens_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Two_Loons_for_Tea'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Boat_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Depth_&_Current'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Satisfact'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Mocket'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Richard_M._Nixon_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Imaginary_Johnny'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Milk_Music'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'H_Is_for_Hellgate'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Seapony'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Novel_Nature'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Pillar_Point_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Posse_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Hobosexual'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Childbirth_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Cardiknox'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'SixTwoSeven'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'The_Heavy_Hearts'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Great_Grandpa'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Giants_in_the_Trees'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'SMP_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Versing'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Medicine_Hat_(band)'}\n",
      "{'website': 'en.wikipedia.org', 'page_title': 'Gun_Outfit'}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "with open(\"WARockBands.jsonl\", 'r') as input_file:\n",
    "    for line in input_file.readlines():\n",
    "        new_data = json.loads(line)\n",
    "        print(new_data)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41db213",
   "metadata": {},
   "source": [
    "4. Well seems like I really can't for the life of me figuring these codes out this week\n",
    " I am so sorry!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947224cf",
   "metadata": {},
   "source": [
    "Second Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2a62a",
   "metadata": {},
   "source": [
    "2.1 Identify an API you will (or might!) want to use for your project.\n",
    "\n",
    "I may use Wikimedia and wikipedia \n",
    "Also I may parse some photos using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93049bea",
   "metadata": {},
   "source": [
    "2.2 Find documentation for that API and include links in your notebook.\n",
    "\n",
    "I think this one:\n",
    "    https://www.wikidata.org/wiki/Wikidata:REST_API\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1269904",
   "metadata": {},
   "source": [
    "2.3 What are the API endpoints you plan to use? What are the parameters you will need to use at that endpoint?\n",
    "\n",
    "(If i remember correctly what endpoint is):\n",
    "    I will parse some written data of the pages related to some specific museum artifacts to use in GPT_2\n",
    "    I will also collect some photos of those artifacts to generate new artifacts with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f9b4b",
   "metadata": {},
   "source": [
    "2.4 Is there a Python module that exists that helps make contact with the API? (See if you can you find example code on how to use it). \n",
    "\n",
    "I am not sure about this really "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1f18e",
   "metadata": {},
   "source": [
    "2.5 Does the API require authentication? Does it need to be approved? \n",
    "\n",
    "    I dont think that I need authentication because Wiki is opensource?\n",
    "    for wikidata I will use: (deleted)\n",
    "    Consumer token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e411074",
   "metadata": {},
   "source": [
    "2.6 Does the API list rate limits? Does it make any requests about how you should use it?\n",
    "\n",
    "Wikipedia's limit is 200 requests per second\n",
    "Wikidata's is 5000 requests per hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4290b85",
   "metadata": {},
   "source": [
    "2.7 Make a single API call, either directly using requests or using the Python module you have used. It doesn't matter for what. The goal is that you can get something'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
