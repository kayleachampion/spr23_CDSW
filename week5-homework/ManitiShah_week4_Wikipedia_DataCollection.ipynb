{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f265e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c7b02b",
   "metadata": {},
   "source": [
    "### Identify a famous person who has been famous for at least a few years and that you have some personal interest in. Use the Wikimedia API to collect page view data from the English Wikipedia article on that person. Now use that data to generate a time-series visualization and include a link to it in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38130035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get page views \n",
    "\n",
    "def get_daily_wikipedia_pageviews(page_title):\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/{page_title}/daily/20130101/20230101\"\n",
    "   \n",
    "    headers = {\n",
    "        'User-Agent': 'python data collection bot by maniti@uw.edu'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data \n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee59a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get monthly page views \n",
    "\n",
    "def get_monthly_wikipedia_pageviews(page_title):\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia.org/all-access/all-agents/{page_title}/monthly/20130101/20230101\"\n",
    "   \n",
    "    headers = {\n",
    "        'User-Agent': 'python data collection bot by maniti@uw.edu'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data \n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a145ecb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_wikipedia_pageviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#collecting data on Harry Stles \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m HarryStylesDataEn \u001b[38;5;241m=\u001b[39m \u001b[43mget_wikipedia_pageviews\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHarry_Styles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m HarryStylesDataEn\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_wikipedia_pageviews' is not defined"
     ]
    }
   ],
   "source": [
    "#collecting data on Harry Stles \n",
    "\n",
    "HarryStylesDataEn = get_wikipedia_pageviews(\"Harry_Styles\")\n",
    "\n",
    "HarryStylesDataEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b955549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry_Styles_Page_Views.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(HarryStylesData)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a1afd",
   "metadata": {},
   "source": [
    "### Identify 2 other languages editions of Wikipedia that have articles on that person. Collect page view data on the article in other languages and create a single visualization that shows how the dynamics and similar and/or different. (Note: My approach involved creating a TSV file with multiple columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Page view data of harry styles in french\n",
    "\n",
    "url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/fr.wikipedia.org/all-access/all-agents/Harry_Styles/monthly/20130101/20230101\"\n",
    "   \n",
    "headers = {\n",
    "        'User-Agent': 'python data collection bot by maniti@uw.edu'\n",
    "    }\n",
    "    \n",
    "response = requests.get(url, headers=headers)\n",
    "    \n",
    "    \n",
    "if response.status_code == 200:\n",
    "        francedata = response.json()\n",
    "        \n",
    "else:\n",
    "        print(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "francedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b13b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry_Styles_France_Page_Views.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(francedata)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a49716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Page view data of harry styles in spanish\n",
    "\n",
    "url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/es.wikipedia.org/all-access/all-agents/Harry_Styles/monthly/20130101/20230101\"\n",
    "   \n",
    "headers = {\n",
    "        'User-Agent': 'python data collection bot by maniti@uw.edu'\n",
    "    }\n",
    "    \n",
    "response = requests.get(url, headers=headers)\n",
    "    \n",
    "    \n",
    "if response.status_code == 200:\n",
    "        spanishdata = response.json()\n",
    "        \n",
    "else:\n",
    "        print(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanishdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Harry_Styles_Spanish_Page_Views.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(spanishdata)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c1ba5",
   "metadata": {},
   "source": [
    "### Collect page view data on the articles about Marvel Comics and DC Comics in English Wikipedia. (If you'd rather replace these examples with some other comparison of popular rivals, that's just as good!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting Pageview data on Marvel and DC Comics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_daily_wikipedia_pageviews('Marvel_Comics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3541df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCComicsData = get_daily_wikipedia_pageviews('DC_Comics')\n",
    "\n",
    "print(DCComicsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7696c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DC_Comics_daily_views.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(DCComicsData)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b37755",
   "metadata": {},
   "outputs": [],
   "source": [
    "MarvelComicsData = get_daily_wikipedia_pageviews('Marvel_Comics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e983cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Marvel_Comics_daily_views.json\", 'w') as my_file:\n",
    "    data_string = json.dumps(MarvelComicsData)\n",
    "    print(data_string, file=my_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948784ad",
   "metadata": {},
   "source": [
    "### Download the file (click \"raw\" and then save the file onto your drive). Now read it in, and request monthly page view data from all of them. If you need some help with loading it in, I've included some sample code at the bottom of this page.\n",
    "### Once you've done this, sum up all of the page views from all of the pages and print out a TSV file with these total numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0d1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "PageTitles = []\n",
    "with open('newARB.jsonl', 'r') as input_file:\n",
    "    for line in input_file.readlines():\n",
    "        new_data = json.loads(line)\n",
    "        PageTitles.append(new_data[\"page_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c78dc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file newARB.jsonl exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"newARB.jsonl\"\n",
    "\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"The file {file_path} exists.\")\n",
    "else:\n",
    "    print(f\"The file {file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3f152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AlternativeRockBands.jsonl\", \"w\") as my_file:\n",
    "        for page_title in PageTitles:\n",
    "            data = get_monthly_wikipedia_pageviews(page_title)\n",
    "            json_string = json.dumps(data)\n",
    "            print(json_string, file=my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc487c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bcbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
