{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1598cbd1",
   "metadata": {},
   "source": [
    " # 1 Wikipedia Page View API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7266d36",
   "metadata": {},
   "source": [
    "1.1 Identify a famous person who has been famous for at least a few years and that you have some personal interest in. Use the Wikimedia API to collect page view data from the English Wikipedia article on that person. Now use that data to generate a time-series visualization and include a link to it in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf26ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbc14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Taylor_Swift_PageViews.json\", 'r') as input_file:\n",
    "    input_data = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de60003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0d52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b9242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'en.wikipedia',\n",
       " 'article': 'Taylor_Swift',\n",
       " 'granularity': 'daily',\n",
       " 'timestamp': '2022043000',\n",
       " 'access': 'all-access',\n",
       " 'agent': 'user',\n",
       " 'views': 13799}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8206d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_timestamp(day): \n",
    "    new_time_stamp = day[0:4] + \"-\" + day[4:6] + \"-\" + day[6:8]\n",
    "    return new_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa629c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_by_day = {}\n",
    "for day_dict in new_data['items']:\n",
    "    day = clean_up_timestamp(day_dict['timestamp'])\n",
    "    views_by_day[day] = day_dict['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e68064",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('view_by_day_Taylor_Swift.tsv', 'w') as output_file:\n",
    "    print(\"day\\tviews\", file=output_file)\n",
    "    for day in views_by_day:\n",
    "        print(f\"{day}\\t{views_by_day[day]}\", file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b8f84",
   "metadata": {},
   "source": [
    "Google sheet: https://docs.google.com/spreadsheets/d/1sKVbRUKkBozIf9Jjc-OoZezTB7sdsDDwULtXTKNOiU0/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b096e",
   "metadata": {},
   "source": [
    "Identify 2 other languages editions of Wikipedia that have articles on that person. Collect page view data on the article in other languages and create a single visualization that shows how the dynamics and similar and/or different. (Note: My approach involved creating a TSV file with multiple columns.)\n",
    "\n",
    "en / es / fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "657f14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "370abae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Taylor_Swift_multiple_language_pageviews.json\", 'r') as input_file:\n",
    "    input_data = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2da6516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b91bd26",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 60040)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 60040)"
     ]
    }
   ],
   "source": [
    "new_data = json.loads(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10d4f77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c9c39c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "new_data['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0d9a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_timestamp(day):\n",
    "    new_time_stamp = day[0:4] + \"-\" + day[4:6] + \"-\" + day[6:8]\n",
    "    return new_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1501d6ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m views_by_day \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      3\u001b[0m     day \u001b[38;5;241m=\u001b[39m clean_up_timestamp(day_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m     views_by_day[day] \u001b[38;5;241m=\u001b[39m day_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviews\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "views_by_day = {}\n",
    "for day_dict in new_data['items']:\n",
    "    day = clean_up_timestamp(day_dict['timestamp'])\n",
    "    views_by_day[day] = day_dict['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28927813",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_file\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[0;32m      4\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m----> 5\u001b[0m     day_dicts \u001b[38;5;241m=\u001b[39m day_dicts \u001b[38;5;241m+\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "day_dicts = []\n",
    "with open(\"Taylor_Swift_multiple_language_pageviews.jsonl\", 'r') as input_file:\n",
    "    for line in input_file.readlines():\n",
    "        new_data = json.loads(line)\n",
    "        day_dicts = day_dicts + new_data[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6cacc42",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mday_dicts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "day_dicts[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9562497",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_views_by_day = {}\n",
    "\n",
    "for day_dict in day_dicts:\n",
    "    day = clean_up_timestamp(day_dict[\"timestamp\"])\n",
    "    \n",
    "    if day in total_views_by_day.keys():\n",
    "        total_views_by_day[day] = total_views_by_day[day] + day_dict[\"views\"]\n",
    "    else:\n",
    "        total_views_by_day[day] = day_dict['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f35aec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('view_by_day_multiple_language.tsv', 'w') as output_file:\n",
    "    print(\"day\\tviews\", file=output_file)\n",
    "    for day in total_views_by_day:\n",
    "        print(f\"{day}\\t{total_views_by_day[day]}\", file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820d210",
   "metadata": {},
   "source": [
    "wasn't able to find the problem :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303624f",
   "metadata": {},
   "source": [
    "Collect page view data on the articles about Marvel Comics and DC Comics in English Wikipedia. (If you'd rather replace these examples with some other comparison of popular rivals, that's just as good!)\n",
    "Which has more total page views in 2022?\n",
    "Can you draw a visualization in a spreadsheet that shows this? (Again, provide a link.)\n",
    "Were there any years when 2022's more popular page was instead the less popular of the two? How many and which ones?\n",
    "Were there any months was this reversal of relative popularity occurred? How many and which ones?\n",
    "How about any days? How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ae2f40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "39e9c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_pageviews(page_title):\n",
    "    # /metrics/pageviews/per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}\n",
    "    url = (\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/\" + \n",
    "           f\"en.wikipedia.org/all-access/user/{page_title}/monthly/20220101/20230101\")\n",
    "    \n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'python collection bot by lucyhu@uw.edu'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if not response.status_code == 200:\n",
    "        print(\"ERROR, request not OK\")\n",
    "    \n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "275fba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMarvel = get_wikipedia_pageviews(\"Marvel_Comics\")\n",
    "dataDC = get_wikipedia_pageviews(\"DC Comics\")\n",
    "\n",
    "with open(\"dataMarvel_views.json\", 'w') as my_Marvelfile:\n",
    "    data_string_Marvel = json.dumps(dataMarvel)\n",
    "    print(data_string_Marvel, file = my_Marvelfile)\n",
    "    \n",
    "with open(\"dataDC_views.json\", 'w') as my_DCfile:\n",
    "    data_string_DC = json.dumps(dataDC)\n",
    "    print(data_string_DC, file = my_DCfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e9af5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69564279",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataMarvel_views.json\", 'r') as marvel_file:\n",
    "    marvel_data = marvel_file.read()\n",
    "    mdata = json.loads(marvel_data)\n",
    "    \n",
    "with open(\"dataDC_views.json\", 'r') as dc_file:\n",
    "    dc_data = dc_file.read()\n",
    "    ddata = json.loads(dc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30d171d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'en.wikipedia',\n",
       " 'article': 'Marvel_Comics',\n",
       " 'granularity': 'monthly',\n",
       " 'timestamp': '2022010100',\n",
       " 'access': 'all-access',\n",
       " 'agent': 'user',\n",
       " 'views': 225335}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "49afbdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'en.wikipedia',\n",
       " 'article': 'DC_Comics',\n",
       " 'granularity': 'monthly',\n",
       " 'timestamp': '2022010100',\n",
       " 'access': 'all-access',\n",
       " 'agent': 'user',\n",
       " 'views': 149880}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddata['items'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ab9a6",
   "metadata": {},
   "source": [
    "There are more views for marvel comics in 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8a7db",
   "metadata": {},
   "source": [
    "Can you draw a visualization in a spreadsheet that shows this? (Again, provide a link.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def clean_up_timestamp(day): \n",
    "    #new_time_stamp = day[0:4] + \"-\" + day[4:6] + \"-\" + day[6:8]\n",
    "    #return new_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedec101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#marvel_pageview = [item['views'] for item in mdata[\"items\"]]\n",
    "#dc_pageview = [item['views'] for item in ddata[\"items\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0e1d7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_pageviews = []\n",
    "dc_pageviews = []\n",
    "\n",
    "for item in mdata['items']:\n",
    "    month = item['timestamp'][:6] \n",
    "    pageviews = item['views']\n",
    "    marvel_pageviews.append((month, pageviews))\n",
    "\n",
    "for item in ddata['items']:\n",
    "    month = item['timestamp'][:6] \n",
    "    pageviews = item['views']\n",
    "    dc_pageviews.append((month, pageviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bc71a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comics_pageviews.tsv', 'w') as output_file:\n",
    "    print(\"day\\tMarvel Comics PageView\\tDC Comics PageView\", file=output_file)\n",
    "    for i in range(len(marvel_pageviews)):\n",
    "        print(marvel_pageviews[i][0] + \"\\t\" + str(marvel_pageviews[i][1]) + \"\\t\" + \n",
    "              str(dc_pageviews[i][1]), file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"comics_pageviews.tsv\", \"w\") as file:\n",
    "    file.write(\"date\\tMarvel Comics PageView\\tDC Comics PageView\\n\")\n",
    "    for date, marvel_comics_view, dc_comics_view in zip(dates, marvel_comics_pageviews, dc_comics_pageviews):\n",
    "        out.write(f\"{day}\\t{marvel_pageview}\\t{dc_pageview}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e5f147",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1nEhPIaByr2ubwYZYuNAgU57QiCmEm5_uVWbM2W7h8lc/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5845521",
   "metadata": {},
   "source": [
    "Were there any years when 2022's more popular page was instead the less popular of the two? How many and which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5258d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7f77e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_pageviews(page_title):\n",
    "    # /metrics/pageviews/per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}\n",
    "    url = (\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/\" + \n",
    "           f\"en.wikipedia.org/all-access/user/{page_title}/monthly/20150101/20230101\")\n",
    "    \n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'python collection bot by lucyhu@uw.edu'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if not response.status_code == 200:\n",
    "        print(\"ERROR, request not OK\")\n",
    "    \n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "62cf9b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[196], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m marvel_data2 \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarveldata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m marveldata \u001b[38;5;241m=\u001b[39m get_wikipedia_pageviews(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarvel_Comics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m marvel_daily \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "marvel_data2 = json.loads(marveldata)\n",
    "marveldata = get_wikipedia_pageviews(\"Marvel_Comics\")\n",
    "\n",
    "marvel_daily = {}\n",
    "marvel_yearly = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c65fb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in marvel_data2['items']:\n",
    "    year = date[\"timestamp\"][0:4]\n",
    "    month = year + \"-\" + date[\"timestamp\"][4:6]\n",
    "    day = date[\"timestamp\"][6:8]\n",
    "\n",
    "    marvel_yearly[day] = date[\"views\"]\n",
    "    if month in marvel_yearly:\n",
    "        marvel_yearly[month] = marvel_yearly[month] + date[\"views\"]\n",
    "    else:\n",
    "        marvel_yearly[month] = date[\"views\"]\n",
    "        \n",
    "    if year in marvel_yearly:        \n",
    "        marvel_yearly[year]  = marvel_yearly[year] + date[\"views\"]\n",
    "    else:\n",
    "        marvel_yearly[year]  = date[\"views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdee34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "19ef2725",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dc_data2 \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdcdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dcdata\u001b[38;5;241m=\u001b[39m get_wikipedia_pageviews(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDC_Comics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m dc_data2 \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(dcdata)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "dc_data2 = json.loads(dcdata)\n",
    "\n",
    "dcdata= get_wikipedia_pageviews(\"DC_Comics\")\n",
    "dc_data2 = json.loads(dcdata)\n",
    "\n",
    "dc_daily = {}\n",
    "dc_yearly ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "52d86905",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc_data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdc_data2\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     year \u001b[38;5;241m=\u001b[39m date[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      3\u001b[0m     month \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m date[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m6\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dc_data2' is not defined"
     ]
    }
   ],
   "source": [
    "for date in dc_data2['items']:\n",
    "    year = date[\"timestamp\"][0:4]\n",
    "    month = year + \"-\" + date[\"timestamp\"][4:6]\n",
    "    day = date[\"timestamp\"][6:8]\n",
    "\n",
    "    dc_yearly[day] = date[\"views\"]\n",
    "    if (month in dc_yearly):\n",
    "        dc_yearly[month] = dc_yearly[month]+ date[\"views\"]\n",
    "    else:\n",
    "        dc_yearly[month] = date[\"views\"]\n",
    "        \n",
    "    if (year in dc_yearly):        \n",
    "        dc_yearly[year]  = dc_yearly[year] + date[\"views\"]\n",
    "    else:\n",
    "        dc_yearly[year]  = date[\"views\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8a825478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc_data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[200], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdc_data2\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dc_data2' is not defined"
     ]
    }
   ],
   "source": [
    "dc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2687d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_timestamp(day): \n",
    "    new_time_stamp = day[0:4] + \"-\" + day[4:6] + \"-\" + day[6:8]\n",
    "    return new_time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8598ef25",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomics\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mviews\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39mfile2)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day_dict \u001b[38;5;129;01min\u001b[39;00m new_data:\n\u001b[1;32m----> 5\u001b[0m     day \u001b[38;5;241m=\u001b[39m clean_up_timestamp(\u001b[43mday_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      6\u001b[0m     views \u001b[38;5;241m=\u001b[39m day_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviews\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m     article \u001b[38;5;241m=\u001b[39m day_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "with open(f\"total_views_comics.tsv\", \"w\") as file2:\n",
    "    print(\"comics\\tdate\\tviews\", file=file2)\n",
    "\n",
    "    for day_dict in new_data:\n",
    "        day = clean_up_timestamp(day_dict['timestamp'])\n",
    "        views = day_dict['views']\n",
    "        article = day_dict['article']\n",
    "        print(day,\"\\t\",article,\"\\t\",views,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "324beb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for year in years:\n",
    "    if (marvel_yearly[year] > dc_yearly[year]):\n",
    "        print(f\"{year}: Marvel\")\n",
    "    else:\n",
    "        print(f\"{year}: DC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c3345",
   "metadata": {},
   "source": [
    "Were there any months was this reversal of relative popularity occurred? How many and which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a12d3",
   "metadata": {},
   "source": [
    "How about any days? How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will have to come to class to see how this code should be writen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca930f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bd005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c9c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13477a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51181a50",
   "metadata": {},
   "source": [
    "I've made this file available which includes list of more than 100 Wikipedia articles about alternative rock bands from Washington state that I built from this category in Wikipedia.[*] It's a .jsonl file. Download the file (click \"raw\" and then save the file onto your drive). Now read it in, and request monthly page view data from all of them. If you need some help with loading it in, I've included some sample code at the bottom of this page.\n",
    "Once you've done this, sum up all of the page views from all of the pages and print out a TSV file with these total numbers.\n",
    "\n",
    "You know the routine by now! Now, make a time series graph of these numbers and include a link in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "224b6d72",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'list_of_washington_alternative_rocks_bands_wikipedia-2023-04-25.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[216], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the list of articles from the JSONL file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m articles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlist_of_washington_alternative_rocks_bands_wikipedia-2023-04-25.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      8\u001b[0m         article \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'list_of_washington_alternative_rocks_bands_wikipedia-2023-04-25.jsonl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Load the list of articles from the JSONL file\n",
    "articles = []\n",
    "with open('list_of_washington_alternative_rocks_bands_wikipedia-2023-04-25.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line.strip())\n",
    "        articles.append(article['title'])\n",
    "\n",
    "# Define the API endpoint and parameters\n",
    "endpoint = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/user/'\n",
    "params = {\n",
    "    'start': '20150101',\n",
    "    'end': '20211231',\n",
    "    'granularity': 'monthly'\n",
    "}\n",
    "\n",
    "# Request the pageviews for all articles and sum them up\n",
    "total_pageviews = {}\n",
    "for article in articles:\n",
    "    url = endpoint + article.replace(' ', '_') + '/monthly/' + params['start'] + '/' + params['end']\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if 'items' in data:\n",
    "        for item in data['items']:\n",
    "            month = item['timestamp'][:6]\n",
    "            pageviews = item['views']\n",
    "            if month in total_pageviews:\n",
    "                total_pageviews[month] += pageviews\n",
    "            else:\n",
    "                total_pageviews[month] = pageviews\n",
    "\n",
    "# Print out the total pageviews in a TSV file\n",
    "with open('alt_rock_pageviews.tsv', 'w') as output_file:\n",
    "    print(\"Month\\tTotal Pageviews\", file=output_file)\n",
    "    for month, pageviews in sorted(total_pageviews.items()):\n",
    "        print(month + '\\t' + str(pageviews), file=output_file)\n",
    "\n",
    "# Make a time series graph using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [int(month) for month in total_pageviews.keys()]\n",
    "y = list(total_pageviews.values())\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Pageviews')\n",
    "plt.title('Total Pageviews of Alternative Rock Bands from Washington State on English Wikipedia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9ba52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d6089ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am SO Sorry I don't think I quiet understand what I am doing at this point I tried to use Chatgpt but it still did not make sense to me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f7669",
   "metadata": {},
   "source": [
    "# 2 Starting on your projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9d794",
   "metadata": {},
   "source": [
    "Identify an API you will (or might!) want to use for your project.\n",
    "Find documentation for that API and include links in your notebook.\n",
    "What are the API endpoints you plan to use? What are the parameters you will need to use at that endpoint?\n",
    "Is there a Python module that exists that helps make contact with the API? (See if you can you find example code on how to use it).\n",
    "If so, download it, install it, and import it into your notebook.\n",
    "Does the API require authentication? Does it need to be approved?\n",
    "If so, sign up for a developer account and get your keys. (Do this early because it often takes time for these accounts to be approved.)\n",
    "Does the API list rate limits? Does it make any requests about how you should use it?\n",
    "Make a single API call, either directly using requests or using the Python module you have used. It doesn't matter for what. The goal is that you can get something'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795ed5e",
   "metadata": {},
   "source": [
    "#My initial idea did not work out as Mako mentioned the problem might be too easy to work on. So I came up with another idea, but will talk to Mako on Monday since I did not came to school last week and did not feel good last week. I think I am a little behind with this class. And I am really confused on some of the coding questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191be7a6",
   "metadata": {},
   "source": [
    "i am thinking about working on topics about a youtube channel that I started years ago. so I was hoping to get some insights on this how this channel is performing and maybe what are the best performing videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5bfb8",
   "metadata": {},
   "source": [
    "The api for youtube is https://developers.google.com/youtube/v3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58109694",
   "metadata": {},
   "source": [
    "I actualy have lots of videos under that account, so I was thinking to give it a limit on the time. I was thinking to look into a specific year. Maybe 2022, how this account has been performed in that year. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3dc2b5",
   "metadata": {},
   "source": [
    "I am looking more into it and it seems like I will need to use the API key with youtube and since I hope to see the data for my channel, I don;t think there will be a problem with the authority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e602e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d84ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4142ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18565b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d5600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
